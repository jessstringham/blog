{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMM exact inference continued: Viterbi\n",
    "\n",
    "This is a short post that continues from [the more-detailed alpha recursion HMM post](2018-05-02-hmm-alpha-recursion.ipynb). In this post I'll implement Viterbi like Barber does. Like before, I'm porting the MatLab code from [\"Bayesian Reasoning and Machine Learning\"](http://www.cs.ucl.ac.uk/staff/d.barber/brml/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nb_code.hmm_alpha_recursion as prev_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper functions you can skip over :D\n",
    "SAVE = True\n",
    "def maybe_save_plot(filename):\n",
    "    if SAVE:\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('images/' + filename, bbox_inches=\"tight\")\n",
    "\n",
    "def hide_ticks(plot):\n",
    "    plot.axes.get_xaxis().set_visible(False)\n",
    "    plot.axes.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viterbi algorithm in HMMs using message passing\n",
    "\n",
    "The Viterbi algorithm finds the most-likely path $h_{1:T}$ for the visibles $v_{1:T}$, where $T$ is the timestep of the last observed visible.\n",
    "The algorithm takes in the visibles $v_{1:T}$, the initial state $p(h_1)$, the transition probabilities $p(h_{t} \\mid h_{t - 1})$, and the emission probabilities $p(v_t \\mid h_t)$, and returns the list of most-likely hidden states $h_{1:T}$. \n",
    "\n",
    "I generated the required probabilities in the [alpha recursion HMM post](2018-05-02-hmm-alpha-recursion.ipynb).\n",
    "\n",
    "### Algorithm\n",
    "\n",
    "Barber frames the Viterbi algorithm as message passing using the max-product algorithm.\n",
    "\n",
    "This version of the algorithm begins at the end of the hidden states ($h_T$), and computes an incoming message from future states. The message is meant to represent the effect of maximizing over those states.\n",
    "Barber gives the messages as:\n",
    "\n",
    "$$\\mu(h_T) = 1$$\n",
    "\n",
    "$$\\mu(h_{t - 1}) = \\max_{h_t} p(v_t \\mid h_t)p(h_t \\mid h_{t - 1})\\mu(h_t).$$\n",
    "\n",
    "Once the messages are computed, the algorithm then computes the most-likely state for $h_1$, and uses that to compute the most-likely state for $h_2$ and so on. It basically maximizes the marginal of $p(h_t|v_{1:T})$ and then uses the most-likely state for $h_t$ in the transition matrix for computing $p(h_{t + 1}|v_{1:T})$ so it returns a valid path.\n",
    "\n",
    "$$h_1^* = \\max_{h_1} p(v_1 \\mid h_1)p(h_1)\\mu(h_1)$$\n",
    "\n",
    "$$h_t^* = \\max_{h_t} p(v_t \\mid h_t)p(h_t \\mid h_{t - 1}^*)\\mu(h_t).$$\n",
    "\n",
    "Now in Python!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15  9  3  2  1  2  3  4 10  9]\n"
     ]
    }
   ],
   "source": [
    "def viterbi(visibles, p_hidden_start, p_transition, p_emission):\n",
    "    num_timestamps = visibles.shape[0]\n",
    "    num_hidden_states = p_transition.shape[0]\n",
    "    \n",
    "    # messages[t] corresponds to mu(h_t), which is the message coming into h_t\n",
    "    messages = np.zeros((num_timestamps, num_hidden_states))\n",
    "    \n",
    "    most_likely_states = np.zeros((num_timestamps,), dtype=int)\n",
    "\n",
    "    # The message coming into the last node is 1 for all states\n",
    "    messages[-1] = np.ones(num_hidden_states)\n",
    "\n",
    "    # normalize!\n",
    "    messages[-1] /= np.sum(messages[-1])\n",
    "    \n",
    "    # Compute the messages!\n",
    "    for t in range(num_timestamps - 1, 0, -1):\n",
    "        # use the data at time t to make mu[h_{t - 1}]\n",
    "        \n",
    "        # compute max p(v|h)p(h|h)mu(h)!\n",
    "        \n",
    "        # compute p(v|h)mu(h)\n",
    "        message_and_emission = messages[t] * p_emission[visibles[t]]\n",
    "        \n",
    "        # compute p(v|h)p(h|h)mu(h)\n",
    "        # message_and_emission.reshape(-1, 1): new_state x 1\n",
    "        # np.tile(...): new_state x old_state\n",
    "        # p_transition: new_state x old_state\n",
    "        # np.tile(...) * p_transition: new_state x old_state\n",
    "        all_h_ts = np.tile(\n",
    "            message_and_emission.reshape(-1, 1),\n",
    "            (1, num_hidden_states)\n",
    "        ) * p_transition\n",
    "        \n",
    "        # the message is the value from the highest h_t\n",
    "        messages[t - 1] = np.max(all_h_ts, axis=0)\n",
    "        \n",
    "        # and normalize\n",
    "        messages[t - 1] /= np.sum(messages[t - 1])\n",
    "    \n",
    "    # now from the beginning! compute h_t* using these messages\n",
    "    \n",
    "    # argmax will give us the state.\n",
    "    # argmax p(v_1|h_1)p(h_1)mu(h_1)\n",
    "    most_likely_states[0] = np.argmax(\n",
    "        p_hidden_start \n",
    "        * p_emission[visibles[0]] \n",
    "        * messages[0]\n",
    "    )\n",
    "    \n",
    "    for t in range(1, num_timestamps):\n",
    "        # argmax_h_t p(v_t|h_t)p(h_t|h_{t - 1})mu(h_t)\n",
    "        most_likely_states[t] = np.argmax(\n",
    "            p_emission[visibles[t], :]\n",
    "            * p_transition[:, most_likely_states[t - 1]] \n",
    "            * messages[t]\n",
    "        )\n",
    "    \n",
    "    return most_likely_states\n",
    "\n",
    "most_likely_states = viterbi(\n",
    "    prev_post.visibles, \n",
    "    prev_post.p_hidden_start,\n",
    "    prev_post.p_transition,\n",
    "    prev_post.p_emission,\n",
    ")\n",
    "\n",
    "print(most_likely_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing\n",
    "\n",
    "I can plot the most-likely states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, all_axs = plt.subplots(4, prev_post.timesteps, figsize=(16, 4))\n",
    "all_axs = all_axs.T\n",
    "\n",
    "VISIBLES = 0\n",
    "TRUE_STATES = 1\n",
    "FILTERING = 2\n",
    "VITERBI = 3\n",
    "\n",
    "all_axs[0][VISIBLES].set_title('Visibles', x=-0.5, y=0.2)\n",
    "all_axs[0][TRUE_STATES].set_title('Actual', x=-0.5, y=0.4)\n",
    "all_axs[0][FILTERING].set_title('Filtering', x=-0.5, y=0.4)\n",
    "all_axs[0][VITERBI].set_title('Viterbi', x=-0.5, y=0.4)\n",
    "\n",
    "for i, (axs, hidden, visible, alpha, viterbi) in enumerate(zip(\n",
    "    all_axs, \n",
    "    prev_post.hiddens, \n",
    "    prev_post.visibles, \n",
    "    prev_post.alphas,\n",
    "    most_likely_states,\n",
    ")):\n",
    "    axs[VISIBLES].imshow([prev_post.map_visible_state_to_bump_creak[visible]], cmap='gray', vmin=0)\n",
    "    hide_ticks(axs[VISIBLES])    \n",
    "    \n",
    "    axs[TRUE_STATES].imshow(prev_post.plot_state_in_room(hidden), cmap='gray')\n",
    "    hide_ticks(axs[TRUE_STATES])\n",
    "    \n",
    "    axs[FILTERING].imshow(alpha.reshape(prev_post.height, prev_post.width))\n",
    "    hide_ticks(axs[FILTERING])      \n",
    "\n",
    "    axs[VITERBI].imshow(prev_post.plot_state_in_room(viterbi), cmap='gray')\n",
    "    hide_ticks(axs[VITERBI])   \n",
    "    \n",
    "maybe_save_plot('2018-05-13-viterbi')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
